{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KjelleJ/enkla-ai-experiment/blob/main/AX10_katt_eller_hund.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "complex-orientation",
      "metadata": {
        "id": "complex-orientation"
      },
      "source": [
        "---\n",
        "# Katt eller hund?\n",
        "Djupinlärning var tidigt framgångsrikt med klassificering av bilder. 2014 startade **Kaggle** en tävling där deltagarna skulle klassificera bilder av katter och hundar. Klasserna var katt och hund. Vinnarna använde djupinlärning som 2014 var ganska nytt. 95% noggrannhet var ett toppresultat. 25,000 bilder användes för träningen, 12,500 på katter och 12,500 på hundar.\n",
        "\n",
        "Vi ska använda betydligt färre bilder. Att inte använda så många bilder är egentligen ett svårare men ett mera realistiskt problem eftersom det inte är lätt att få tag på tusentals relevanta bilder.\n",
        "\n",
        "Vi kommer att amvända bilder på katter och hundar från Kaggle\n",
        "\n",
        "*   För **träning**: Bilder på 250 katter och 250 hundar.\n",
        "*   För **validering** Bilder på 125 katter och 125 hundar. Valideringsdata används för att utvärdea modellen under träningen. Modellen tränas inte med valideringsdata.\n",
        "*   För **test** Bilder på 500 katter och 500 hundar.\n",
        "\n",
        "\n",
        "Vi kommer att få bättre resultat än 95% noggrannhet men då använder vi metoder som deltagarna i tävlingen inte kunde använda."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Du bör använda en GPU** - L4 duger bra: Pil uppe till höger, välj 'Ändra körningstyp', sedan välj L4 och spara."
      ],
      "metadata": {
        "id": "H45asMeaUteL"
      },
      "id": "H45asMeaUteL"
    },
    {
      "cell_type": "code",
      "source": [
        "# Hämta bilderna - en zip-fil\n",
        "!rm -f dogs_vs_cats_500.zip*\n",
        "!wget download.gubboit.se/dogs_vs_cats_500.zip"
      ],
      "metadata": {
        "id": "ZKHdFGT1QkX1"
      },
      "id": "ZKHdFGT1QkX1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Packa upp zip-filen\n",
        "!unzip -oq dogs_vs_cats_500.zip"
      ],
      "metadata": {
        "id": "CkN_-9TgQ-2u"
      },
      "id": "CkN_-9TgQ-2u",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "dense-christian",
      "metadata": {
        "id": "dense-christian"
      },
      "source": [
        "## Plotta de tre första hundarna och katterna i träningsdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "saved-yugoslavia",
      "metadata": {
        "scrolled": false,
        "id": "saved-yugoslavia"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i in range(3):\n",
        "    image = Image.open(\"dogs_vs_cats_500/train/cat/cat.\" + str(i) + \".jpg\")\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)\n",
        "for i in range(0, 3):\n",
        "    image = Image.open(\"dogs_vs_cats_500/train/dog/dog.\" + str(i) + \".jpg\")\n",
        "    plt.subplot(2, 3, i + 4)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sensitive-check",
      "metadata": {
        "id": "sensitive-check"
      },
      "source": [
        "## Hjälpfunktioner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "trying-isolation",
      "metadata": {
        "id": "trying-isolation"
      },
      "outputs": [],
      "source": [
        "# Funktion för att skapa datset för träning, validering och test\n",
        "def create_datasets(new_base_dir, size):\n",
        "    from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "    print('Training')\n",
        "    train = image_dataset_from_directory(\n",
        "        new_base_dir + \"/train\",\n",
        "        image_size=size,\n",
        "        batch_size=32)\n",
        "    print('Validation')\n",
        "    validation = image_dataset_from_directory(\n",
        "        new_base_dir + \"/validation\",\n",
        "        image_size=size,\n",
        "        batch_size=32)\n",
        "    print('Test')\n",
        "    test = image_dataset_from_directory(\n",
        "        new_base_dir + \"/test\",\n",
        "        image_size=(size),\n",
        "        batch_size=32)\n",
        "    return train, validation, test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# funktion som plottar tränings-historiken\n",
        "def plot_acc_loss():\n",
        "    import matplotlib.pyplot as plt\n",
        "    acc = history.history[\"accuracy\"]\n",
        "    val_acc = history.history[\"val_accuracy\"]\n",
        "    loss = history.history[\"loss\"]\n",
        "    val_loss = history.history[\"val_loss\"]\n",
        "    epochs = range(1, len(acc) + 1)\n",
        "    plt.plot(epochs, acc, \"bo\", label=\"Training accuracy\")\n",
        "    plt.plot(epochs, val_acc, \"b\", label=\"Validation accuracy\")\n",
        "    plt.title(\"Training and validation accuracy\")\n",
        "    plt.legend()\n",
        "    plt.figure()\n",
        "    plt.plot(epochs, loss, \"bo\", label=\"Training loss\")\n",
        "    plt.plot(epochs, val_loss, \"b\", label=\"Validation loss\")\n",
        "    plt.title(\"Training and validation loss\")\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "LNJEq-3FSK7G"
      },
      "id": "LNJEq-3FSK7G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "needed-government",
      "metadata": {
        "id": "needed-government"
      },
      "source": [
        "---\n",
        "# Transfer learning: Modell för bilder med storleken 160x160 eller 224x224 pixlar\n",
        "Att träna en modell för katt eller hund från scratch tar lång tid och kräver mera data än vi har för att få ett bra resultat. Vi ska i stället använda en smartare teknik **transfer learning** för att få bättre resultat. Transfer learning innebär att vi använder **en färdigtränad modell som bas.** Modellen har tränats med ett visst dataset. Vi ska använda MobileNetV2 som har tränats med datasetet Imagenet. Imagenet har 1000 klasser bl.a. mycket bilder på djur. Vi har bara två klasser (katt eller hund). Vi byter ut några lager i slutet av modellen (för 1000 klasser) så att vi får två klasser. Slutet kallas **toppen**. Vi tränar sedan den nya modellen men bara vikterna i den nya toppen. **Vikterna i basen är frysta**.\n",
        "\n",
        "Vår modell ska använda **data augmentation** (”utökning av data”). Det är en teknik som används för att på konstlad väg öka antalet bilder vid träningen. På så vis kan vi minska risken för överanpassning av modellen till träningsdata och få ett bättre resultat. Data augmentation använder sig av slumpmässig horisontell flip (vänd bilden), rotation och zoomning. Åtminstone i teorin används inte samma bild två gånger vid träningen men bilderna är förstås ganska lika."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Kör först med npix=160 och sedn med npix=224\n",
        "npix=160\n",
        "#npix=224"
      ],
      "metadata": {
        "id": "MLlHfzKPZazD"
      },
      "id": "MLlHfzKPZazD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "norman-cheat",
      "metadata": {
        "id": "norman-cheat"
      },
      "outputs": [],
      "source": [
        "# skapa dataset från \"dogs_vs_cats_500\"\n",
        "train_dataset, validation_dataset , test_dataset = create_datasets(\"dogs_vs_cats_500\", (npix, npix))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definiera basen: MobileNet utan topp och med alla vikter frysta\n",
        "from tensorflow import keras\n",
        "\n",
        "conv_base = keras.applications.MobileNetV2(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=False,\n",
        "    input_shape=(npix, npix, 3))\n",
        "conv_base.trainable = False"
      ],
      "metadata": {
        "id": "CavpCuIdS2OK"
      },
      "id": "CavpCuIdS2OK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_base.summary()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "227iSx3kS170"
      },
      "id": "227iSx3kS170",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "prescribed-effectiveness",
      "metadata": {
        "id": "prescribed-effectiveness"
      },
      "outputs": [],
      "source": [
        "# Definiera den nya toppen. Här tränas alla vikter\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "data_augmentation = keras.Sequential(\n",
        "    [\n",
        "        layers.RandomFlip(\"horizontal\"),\n",
        "        layers.RandomRotation(0.1),\n",
        "        layers.RandomZoom(0.2),\n",
        "    ]\n",
        ")\n",
        "\n",
        "inputs = keras.Input(shape=(npix, npix, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = conv_base(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(256)(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs, outputs)\n",
        "model.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "K6HCyMIPTzwR"
      },
      "id": "K6HCyMIPTzwR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cross-dairy",
      "metadata": {
        "scrolled": false,
        "id": "cross-dairy"
      },
      "outputs": [],
      "source": [
        "# Vi sparar den bästa modellen från träningen på fil\n",
        "if npix==160:\n",
        "    filepath=\"feature_extraction2.keras\"\n",
        "else:\n",
        "    filepath=\"feature_extraction3.keras\"\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=filepath,\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=50,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "least-necessity",
      "metadata": {
        "scrolled": false,
        "id": "least-necessity"
      },
      "outputs": [],
      "source": [
        "# Utvärdera modellen\n",
        "test_model = keras.models.load_model(filepath)\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset, verbose=0)\n",
        "print(f\"Test accuracy: {test_acc:.3f}  Test loss: {test_loss:.3f}\")\n",
        "if npix == 160:\n",
        "  test_loss_160 = test_loss\n",
        "  test_acc_160 = test_acc\n",
        "else:\n",
        "  test_loss_224 = test_loss\n",
        "  test_acc_224 = test_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "weird-casting",
      "metadata": {
        "scrolled": false,
        "id": "weird-casting"
      },
      "outputs": [],
      "source": [
        "# Plotta accuracy och loss från träningen\n",
        "plot_acc_loss()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "structural-jonathan",
      "metadata": {
        "id": "structural-jonathan"
      },
      "source": [
        "## Om du inte har kört med npix=224 gå till början av Transfer Learning och ändra npix=160 till npix=224 och kör med den nya bildstorleken. Annars fortsätt bara..."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Jämför resultat för npix=160 och npix=224\n",
        "print(f\"Bildstorlek 160x160: Test accuracy: {test_acc_160:.3f}  Test loss: {test_loss_160:.3f}\")\n",
        "print(f\"Bildstorlek 224x224: Test accuracy: {test_acc_224:.3f}  Test loss: {test_loss_224:.3f}\")"
      ],
      "metadata": {
        "id": "lMNXV-gwiMN2"
      },
      "id": "lMNXV-gwiMN2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "streaming-hartford",
      "metadata": {
        "id": "streaming-hartford"
      },
      "source": [
        "# Använd modellen för bildstorlek 224x224\n",
        "#### Bilden bör prepareras på samma sätt som vid träningen\n",
        "Vi använde Keras-funktionen image_dataset_from_directory när dataseten skapades. Cat kommer före dog. Då bör cat vara klass 0 och dog klass 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "european-inventory",
      "metadata": {
        "id": "european-inventory"
      },
      "outputs": [],
      "source": [
        "# modell för bilder 224x224\n",
        "test_model = keras.models.load_model(\"feature_extraction3.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "verified-celtic",
      "metadata": {
        "id": "verified-celtic"
      },
      "outputs": [],
      "source": [
        "# funktion för att klassificera bilder\n",
        "def catvsdog(img_path):\n",
        "    import tensorflow as tf\n",
        "    img = plt.imread(img_path)\n",
        "    plt.imshow(img)\n",
        "    # kod från https://keras.io/examples/vision/image_classification_from_scratch/\n",
        "    img = tf.image.resize(img, (224, 224))\n",
        "    img_array = keras.preprocessing.image.img_to_array(img)\n",
        "    # add batch dim\n",
        "    img_array = tf.expand_dims(img_array, 0)\n",
        "    pred =  test_model.predict(img_array, verbose=0)\n",
        "    # binary classification: tf-model returns 0 or 1\n",
        "    if pred == 1: print(\"Hund\")\n",
        "    else: print(\"Katt\")\n",
        "    print(pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "widespread-canal",
      "metadata": {
        "scrolled": true,
        "id": "widespread-canal"
      },
      "outputs": [],
      "source": [
        "# bild nr från 750 till och med 1249\n",
        "import tensorflow as tf\n",
        "catvsdog(\"dogs_vs_cats_500/test/cat/cat.752.jpg\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "stone-lucas",
      "metadata": {
        "id": "stone-lucas"
      },
      "outputs": [],
      "source": [
        "# här blir det kanske fel!?\n",
        "catvsdog(\"dogs_vs_cats_500/test/cat/cat.753.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hundred-timothy",
      "metadata": {
        "id": "hundred-timothy"
      },
      "outputs": [],
      "source": [
        "catvsdog(\"dogs_vs_cats_500/test/dog/dog.1249.jpg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "desperate-literature",
      "metadata": {
        "id": "desperate-literature"
      },
      "source": [
        "---\n",
        "# MobileNet utan träning med cats_vs_dogs"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "seeing-rwanda",
      "metadata": {
        "id": "seeing-rwanda"
      },
      "source": [
        "### Imagenet klasser: https://gist.github.com/ageitgey/4e1342c10a71981d0b491e1b8227328b\n",
        "### Katter 281-285, tamhundar 151-268, totalt 1000 klasser\n",
        "\n",
        "MobileNet/Imagenet är bra på hundar och katter. Det finns 5 klasser för olika raser av katter och 118 klasser för olika hundraser. Vilken noggrannhet får vi om använder modellen som den är utan träning? Vi låter modellen göra prediktioner för våra testdata. Om prediktionen blir någon av kattklasserna säger vi att det är en katt. Motsvarande för hundklasserna. Om något annat så är det fel. Det hela fixas med lite Python-kod."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "exterior-tutorial",
      "metadata": {
        "id": "exterior-tutorial"
      },
      "outputs": [],
      "source": [
        "# HELA MobileNetV2\n",
        "mobile_net = keras.applications.MobileNetV2(\n",
        "    weights=\"imagenet\",\n",
        "    include_top=True,\n",
        "    input_shape=(160, 160, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "designed-herald",
      "metadata": {
        "scrolled": false,
        "id": "designed-herald"
      },
      "outputs": [],
      "source": [
        "mobile_net.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "outstanding-belize",
      "metadata": {
        "id": "outstanding-belize"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "hund = 0\n",
        "for i in range(750, 1250):\n",
        "    pimage = plt.imread(\"dogs_vs_cats_500/test/dog/dog.\" + str(i) + \".jpg\")\n",
        "    # lägg till batch- dimension, normalisera till (0.0, 1.0)\n",
        "    pimage = pimage.astype(np.float32)[np.newaxis, ...] / 255.\n",
        "    # ändra storlek till 160x160\n",
        "    pimage = tf.image.resize(pimage, (160, 160))\n",
        "    # bestäm klass\n",
        "    pred = (mobile_net.predict(pimage, verbose=0)).argmax()\n",
        "    if pred >= 151 and pred <= 268: hund = hund + 1\n",
        "print(str(hund) + \" hundar av 500 korrekt klassificerade. Noggrannhet=\" + str(hund/500))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "signed-acting",
      "metadata": {
        "scrolled": true,
        "id": "signed-acting"
      },
      "outputs": [],
      "source": [
        "katt = 0\n",
        "for i in range(750, 1250):\n",
        "    pimage = plt.imread(\"dogs_vs_cats_500/test/cat/cat.\" + str(i) + \".jpg\")\n",
        "    pimage = pimage.astype(np.float32)[np.newaxis, ...] / 255.\n",
        "    pimage = tf.image.resize(pimage, (160, 160))\n",
        "    pred = (mobile_net.predict(pimage, verbose=0)).argmax()\n",
        "    if pred >= 281 and pred <= 285: katt = katt + 1\n",
        "print(str(katt) + \" katter av 500 korrekt klassificerade. Noggrannhet=\" + str(katt/500))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "literary-litigation",
      "metadata": {
        "id": "literary-litigation"
      },
      "outputs": [],
      "source": [
        "print(\"Noggrannhet totalt=\" + str((hund + katt)/1000))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# Som jämförelse: Träna en enkel modell från scratch med lika mycket data\n",
        "---"
      ],
      "metadata": {
        "id": "mA31pbai1owg"
      },
      "id": "mA31pbai1owg"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dental-green",
      "metadata": {
        "id": "dental-green"
      },
      "outputs": [],
      "source": [
        " # definiera en enkel modell med 3 conv-lager\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = keras.Input(shape=(224, 224, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "x = layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "x = layers.MaxPooling2D(pool_size=2)(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "# sigmoid eftersom modellen har två klasser\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model3 = keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# binary_crossentropy eftersom modellen har 2 klasser\n",
        "model3.compile(loss=\"binary_crossentropy\",\n",
        "              optimizer=\"rmsprop\",\n",
        "              metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "        filepath=\"model3_from_scratch.keras\",\n",
        "        save_best_only=True,\n",
        "        monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "model3.summary()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "eOUWkiKp184o"
      },
      "id": "eOUWkiKp184o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Träna vår enkla modell från scratch i 100 epoker"
      ],
      "metadata": {
        "id": "8RSddDWk2idU"
      },
      "id": "8RSddDWk2idU"
    },
    {
      "cell_type": "code",
      "source": [
        "history = model3.fit(\n",
        "    train_dataset,\n",
        "    epochs=100,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "VP_yzo603i0Q"
      },
      "id": "VP_yzo603i0Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utvärdera modellen"
      ],
      "metadata": {
        "id": "ILH69a6v31VV"
      },
      "id": "ILH69a6v31VV"
    },
    {
      "cell_type": "code",
      "source": [
        "# ladda och utvärdera bästa modellen (0.8250 med 2000 filer)\n",
        "test_model = keras.models.load_model(\"model3_from_scratch.keras\")\n",
        "test_loss, test_acc = test_model.evaluate(test_dataset)\n",
        "print(f\"Test accuracy: {test_acc:.3f}\")"
      ],
      "metadata": {
        "id": "owUeTpiB18sl"
      },
      "id": "owUeTpiB18sl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_acc_loss()"
      ],
      "metadata": {
        "id": "BmvXrDF_18hE"
      },
      "id": "BmvXrDF_18hE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plottarna visar en tydlig överanpassning - kurvorna för träning och validering divergerar. För att få ett bättre resultat: Öka antalet träningsbilder och/eller använd en mera avancerad modell..."
      ],
      "metadata": {
        "id": "BSB79h04ndll"
      },
      "id": "BSB79h04ndll"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xui2zPyT18KB"
      },
      "id": "xui2zPyT18KB",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}